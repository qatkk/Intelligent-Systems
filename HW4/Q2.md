# Clustering Algorithm Implementation 
In this question, we intend to implement the algorithm of the first part of the first question using code. As we explained earlier, this algorithm consists of several parts and tries to optimize the following cost function in each iteration.

$$\Sigma _ {i = 0 } ^n min_{\mu_j \in C} (||x_i - \mu_j|| ^2)$$

This cost function is optimized in this algorithm by moving the centers of the clusters automatically.
Another challenge of this algorithm is to select the right number of clusters for the data, for which there are various methods. In this section, we determine the optimal value of k using the elbow method.
figure below, shows the code for the function of this algorithm.

<img width="470" alt="image" src="https://user-images.githubusercontent.com/43328710/175361084-ef3bdb0d-ce81-48a3-ab80-a148c4d1a312.png">

## Efect of the Number of Clusters
As mentioned earlier, changing the centers of the algorithm inherently reduces the value of the cost function, but due to the random selection of centers and the greed of the algorithm, the resulting clustering is not necessarily optimal. To improve the performance of the algorithm, the iteration of the algorithm and the selection of the least value of the cost function among the iterations along with determining the optimal k can give us the desired performance. Figure 2-2 shows the value of the cost function executed at one time and for 16 times the algorithm center change. At the end and in the 16th, the center change of the algorithm is fixed and gives us the value of the optimal centers.

<img width="378" alt="image" src="https://user-images.githubusercontent.com/43328710/175361386-083f88f2-1fbd-4360-8f2f-d0109a94abc8.png">
To determine the best number of clusters, as mentioned earlier, we use the elbow method. In this way, we calculate the value of the internal distances of the clusters for the number of different clusters and draw them in a graph, the point that changes the slope of the graph or in other words forms the elbow of the graph determines the optimal number of clusters for us.
Note that increasing the number of clusters helps improve performance to some extent, but also increases computations. Thus, Figure 3-2 shows the code output for different values of k and the optimal value using the method is 10.

<img width="544" alt="image" src="https://user-images.githubusercontent.com/43328710/175361622-fbe42bbb-3757-4311-8702-4e5abd2dfda5.png">

<img width="430" alt="image" src="https://user-images.githubusercontent.com/43328710/175361704-0f618f9a-7c62-400b-9d20-0b1353e52c5c.png">

According to the formula for calculating the inner distance of the clusters to the outer distance of the clusters and the description of the master, minimizing the amount of internal distance has led to maximizing the outer distances of the clusters and no need for further calculations.

## Efect of the Number of Iterations 

In this section, we report and analyze the mean and variance of the cost function value for 150 repetitions of the algorithm.

- Table of means and variances with respect to K 
<img width="614" alt="image" src="https://user-images.githubusercontent.com/43328710/175362089-a92bddfc-682e-40a2-8a1c-0277041edcac.png">

Due to the randomness of the initial points in this algorithm, the repetition of the experiment does not necessarily constitute an ascending or descending trend. Simply repeating the test can only allow us to select the best performance and related centers and thus be able to have optimal performance.
The randomness of the performance and the above description can also be intuitively deduced from figure below. 
- Plot of the cost function with respect to iteration
<img width="392" alt="image" src="https://user-images.githubusercontent.com/43328710/175362346-deeee73d-7e77-4ab4-b87b-2f6c3f714221.png">
